Promptza â€“ Local Pizza Review AI Assistant
Promptza is a fully local AI assistant that answers natural language questions about a pizza restaurant based on realistic customer reviews.

It uses:

ğŸ§  Ollama â€“ to run LLaMA 3 or other LLMs locally

ğŸ”— LangChain â€“ for prompt chaining and agent logic

ğŸ” ChromaDB â€“ for fast vector-based semantic search

ğŸ“„ CSV Data â€“ real restaurant reviews as the knowledge base

No API keys. No cloud. 100% offline and free.

ğŸš€ Features:

ğŸ” Ask questions like "Howâ€™s the service?" or "Is the pizza spicy?"

ğŸ§  LLM finds relevant reviews and generates smart answers

ğŸ’¾ All runs locally â€“ perfect for learning and privacy

ğŸ› ï¸ Easily customizable for other datasets/domains

.
â”œâ”€â”€ main.py                      # Chat interface and LangChain logic
â”œâ”€â”€ vector.py                    # Handles embedding + vector search
â”œâ”€â”€ realistic_restaurant_reviews.csv   # Dataset of customer reviews
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ README.md                    # This file


ğŸ›  Setup Instructions
1. Clone the repo
git clone https://github.com/ShivakumarJalihal/Promptza.git
cd Promptza

3. Create and activate a virtual environment
python -m venv venv
venv\Scripts\activate     # On Windows
# source venv/bin/activate  # On Mac/Linux

3. Install dependencies
pip install -r requirements.txt

5. Run the assistant
python main.py
Make sure Ollama is installed and the model (e.g., llama3) is pulled.

ğŸ§  Sample Questions to Ask
- "What do people say about the staff?"

- "Are the prices reasonable?"

- "Howâ€™s the taste of the cheese pizza?"

ğŸ“Œ To-Do / Improvements
 - Add a basic GUI using Tkinter or Streamlit

 - Add logging or analytics

 - Support multiple datasets
